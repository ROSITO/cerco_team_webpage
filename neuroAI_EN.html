<div class="team-page-outer"><style>:root{--bg:#f6f7f8;--card:#ffffff;--ink:#1f2937;--muted:#6b7280;--brand:#0f766e;--line:#e5e7eb;--maxw:1200px;}.team-page{background:var(--bg);color:var(--ink);padding:24px;border:1px solid var(--line);border-radius:10px;max-width:var(--maxw);margin:0 auto;}.team-page .title{font-size:clamp(1.6rem,2.6vw,2.2rem);margin:0 0 18px;font-weight:700}.team-grid{display:grid;grid-template-columns:320px 1fr;gap:24px}@media (max-width:980px){.team-grid{grid-template-columns:1fr}}.card{background:var(--card);border:1px solid var(--line);border-radius:10px;padding:16px}.section-title{font-size:1.1rem;font-weight:700;margin:0 0 12px;padding-bottom:8px;border-bottom:2px solid var(--line)}.leaders{display:grid;grid-template-columns:1fr 1fr;gap:12px;margin-bottom:16px}@media (max-width:480px){.leaders{grid-template-columns:1fr}}.leader{display:grid;grid-template-rows:auto 1fr;gap:8px;text-align:center}.leader img{width:100%;aspect-ratio:1/1;object-fit:cover;border-radius:8px;border:1px solid var(--line)}.leader .name{font-weight:700}.leader .role{color:var(--muted);font-size:.95rem}.team-lists .block{margin:12px 0}.team-lists .block strong{display:block;margin-bottom:6px}.team-lists ul{margin:0;padding-left:18px}.team-lists li{margin:2px 0}.projects{display:grid;grid-template-columns:repeat(4,1fr);gap:12px}@media (max-width:1280px){.projects{grid-template-columns:repeat(3,1fr)}}@media (max-width:980px){.projects{grid-template-columns:repeat(2,1fr)}}@media (max-width:520px){.projects{grid-template-columns:1fr}}.project{position:relative;min-height:180px;border-radius:10px;overflow:hidden;border:1px solid var(--line);background:#ddd center/cover no-repeat}.project a{position:absolute;inset:0;display:block;text-decoration:none}.project .label{position:absolute;left:0;right:0;bottom:0;padding:10px 12px;background:rgba(255,255,255,.88);font-size:.95rem;line-height:1.3;color:var(--ink)}.publist{list-style:none;padding:0;margin:0}.publist li{padding:10px 0;border-bottom:1px dashed var(--line)}.publist a{text-decoration:underline;color:var(--brand)}.funders{display:flex;flex-wrap:wrap;gap:16px;align-items:center}.funders img{height:42px;width:auto;filter:grayscale(30%);opacity:.95}.note{color:var(--muted);font-size:.95rem}</style><div class="team-page"><h1 class="title">NeuroAI: cross-pollination between Neuroscience and Artificial Intelligence</h1><div class="team-grid"><aside class="col-left"><section class="card"><h2 class="section-title">Team Leader</h2><div class="leaders"><div class="leader"><img src="https://cerco.cnrs.fr/wp-content/uploads/2019/05/tim-e1561107709774.png" alt="Team Leader"><div class="name">Timothée Masquelier</div><div class="role">Directeur de recherche (DR2)</div><div class="note">timothee.masquelier@cnrs.fr</div></div></div></section><section class="card team-lists"><h2 class="section-title">Team Members</h2><div class="block"><strong>Researchers</strong><ul><li>Andrea Alamia (CR)</li><li>Victor Boutin (CR)</li><li>Timothée Masquelier (DR2)</li><li>Rufin VanRullen (DR1)</li></ul></div><div class="block"><strong>Associated researchers</strong><ul><li>Arnaud Delorme (Pr UCSD)</li><li>Thomas Serre (Pr Brown Univ.)</li></ul></div><div class="block"><strong>Research Engineer</strong><ul><li>Leslie Marie-Louise</li></ul></div><div class="block"><strong>PhD students/Postdocs</strong><ul><li>Grégoire Audry</li><li>Jan Erik Bellingrath</li><li>Roland Bertin-Johannet</li><li>Jorge Chang</li><li>Yusuf Elhelw</li><li>Luca Gonzalez-Sommer</li><li>Raja Kumar</li><li>Bastien Lelan</li><li>Jean-Félix Maestrati</li><li>Adrien Marque</li><li>Léopold Maytié</li><li>Alexandre Quéant</li><li>Ulysse Rançon</li><li>Tomas de Udaeta</li></ul></div></section><section class="card"><h2 class="section-title">Research Themes</h2><ul><li>Artificial Intelligence</li><li>Deep learning</li><li>Computational neuroscience</li></ul></section></aside><div class="col-right"><section class="card"><h2 class="section-title">Presentation</h2><p>NeuroAI embodies the cross-pollination between Neuroscience and Artificial Intelligence (AI). On the one hand, the team leverages the staggering recent breakthroughs in AI tools to model brain processing more accurately – for example, visual processing or mental simulations – or to find patterns in vast amounts of fMRI, EEG, and MEG data, and to relate them to stimulus features, perception, cognition, behavior, and well-being. On the other hand, all the recent AI models are black boxes, still limited in generalization, and have an enormous computational cost (energy, chips, data, etc.). Therefore, another objective is to seek inspiration from the brain to design more interpretable, robust, and frugal AIs, for example, by incorporating spikes, more human-like visual representations, or a cognitive architecture, presumably used by the brain and known as the global workspace.</p></section><section class="card"><h2 class="section-title">Projects</h2><div class="projects"><figure class="project" style="background-image:url('https://via.placeholder.com/800x600.png?text=Neurogram');"><a href="#"></a><figcaption class="label"><strong>Neurogram</strong><br>Neuro-AI guided objective hearing assessment and hearing loss compensation</figcaption></figure><figure class="project" style="background-image:url('http://cerco.cnrs.fr/wp-content/uploads/2025/11/NeuroAI-project2-1.png');"><a href="#"></a><figcaption class="label"><strong>ERC GLoW</strong><br>The Global Latent Workspace: Towards AI models of flexible cognition</figcaption></figure><figure class="project" style="background-image:url('https://via.placeholder.com/800x600.png?text=Chaire+C3PO');"><a href="#"></a><figcaption class="label"><strong>ANITI Chair C3PO</strong><br>Cobots with Conversation, Cognition and Perception</figcaption></figure><figure class="project" style="background-image:url('https://via.placeholder.com/800x600.png?text=EEG-FM');"><a href="#"></a><figcaption class="label"><strong>EEG-FM</strong><br>Tuning EEG Fundation Models to Brain Dynamics</figcaption></figure><figure class="project" style="background-image:url('https://via.placeholder.com/800x600.png?text=RiMind');"><a href="#"></a><figcaption class="label"><strong>RiMind</strong><br>Experience-Shaped Geometry of Cognition : The Riemannian Mind Hypothesis</figcaption></figure><figure class="project" style="background-image:url('http://cerco.cnrs.fr/wp-content/uploads/2025/11/NeuroAI-project6.png');"><a href="#"></a><figcaption class="label"><strong>OSCI-PRED</strong><br>A Predictive Coding Perspective on Brain Dynamics: the case of oscillatory traveling waves</figcaption></figure></div></section><section class="card"><h2 class="section-title">Publications (selection)</h2><ul class="publist"><li>Béthune, L., Vigouroux, D., Du, Y., VanRullen, R., Serre, T., & Boutin, V. (2025). <a href="https://arxiv.org/abs/2505.18230">Follow the Energy, Find the Path: Riemannian Metrics from Energy-Based Models</a>. <em>NeuRIPS</em>.</li><li>Ferrante, M., Boccato, T., Toschi, N., & VanRullen, R. (2025). <a href="https://www.nature.com/articles/s42003-025-08706-4">Evidence for compositionality in fMRI visual representations via Brain Algebra</a>. <em>Communications Biology</em>.</li><li>Schwenk, J.C.B., & Alamia, A. (2025). <a href="https://doi.org/10.1371/journal.pcbi.1013294">A hierarchical multiscale model of forward and backward alpha-band traveling waves in the visual system</a>. <em>PLOS Computational Biology</em>.</li><li>Rançon, U., Masquelier, T., Cottereau, B.R. (2025). <a href="#">Temporal recurrence as a general mechanism to explain neural responses in the auditory system</a>. <em>Communications Biology</em>.</li><li>Hammouamri, I., Khalfaoui-Hassani, I., Masquelier, T. (2024). <a href="https://openreview.net/forum?id=4r2ybzJnmN">Learning Delays in Spiking Neural Networks using Dilated Convolutions with Learnable Spacings</a>. <em>ICLR</em>.</li><li>Devillers, B., Maytié, L., & VanRullen, R. (2024). <a href="https://ieeexplore.ieee.org/abstract/document/10580966">Semi-supervised multimodal representation learning through a global workspace</a>. <em>IEEE Transactions on Neural Networks and Learning Systems</em>.</li><li>Alamia, A., Gordillo, D., Chkonia, E., Roinishvili, M., Cappe, C., & Herzog, M. H. (2024). <a href="https://doi.org/10.1016/j.biopsych.2024.11.014">Oscillatory traveling waves provide evidence for predictive coding abnormalities in schizophrenia</a>. <em>Biological Psychiatry</em>.</li><li>Boutin, V., Mukherji, R., Agrawal, A., Muzellec, S., Fel, T., Serre, T. and VanRullen, R. (2024). <a href="https://arxiv.org/abs/2406.06079">Latent Representation Matters: Human-like Sketches in One-shot Drawing Tasks</a>. <em>NeuRIPS</em>.</li><li>Delorme, A. (2023). <a href="https://doi.org/10.1038/s41598-023-27528-0">EEG is better left alone</a>. <em>Scientific Reports</em>.</li><li>Truong, D., Khalid, M. A., & Delorme, A. (2023). <a href="https://doi.org/10.1109/BIBM58861.2023.10385525">Deep learning applied to EEG data with different montages using spatial attention</a>. <em>IEEE BIBM</em>.</li></ul></section><section class="card"><h2 class="section-title">Funding</h2><div class="funders"><a href="#"><img src="https://anr.fr/typo3conf/ext/anr_skin/Resources/Public/assets/img/logo-anr-fr-20ans-2x.png" alt="ANR"></a><a href="#"><img src="https://erc.europa.eu/sites/default/files/inline-images/HE%20logo.png" alt="ERC"></a><a href="#"><img src="https://aniti.univ-toulouse.fr/wp-content/uploads/2023/06/Capture-decran-2023-06-26-a-09.59.26-1.png" alt="ANITI"></a></div></section></div></div></div></div>
